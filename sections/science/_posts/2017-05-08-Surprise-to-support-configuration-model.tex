Let's start with some notation:

\begin{itemize}[<+->]
\tightlist
\item
  \[G\] undirected graph, unweighted, no self-loops, no multiedges.
\item
  \[n\] number of nodes
\item
  \[m\] number of edges
\item
  \[C\] number of communities (or blocks)
\item
  \[c\] index of c-th community (or block)
\item
  \[p\] number of node pairs \[p=\binom{n}{2}\].
\item
  \[n_c\] number of nodes in community \[c\].
\item
  \[m_c\] number of edges in community \[c\].
\item
  \[p_c\] number of pairs in community \[c\].
\item
  \[m_\zeta\] total number of intracluster edges \[m_\zeta=\sum_c m_c\].
\item
  \[p_\zeta\] total number of intracluster pairs \[p_\zeta=\sum_c p_c\].
\item
  \[m-m_\zeta\] total number of intercluster edges.
\item
  \[p-p_\zeta\] total number of intercluster pairs.
\end{itemize}

The discrete version of Surprise is then defined as:

\[ S = \sum \limits_i ^{m_\zeta} \dfrac{\binom{p_\zeta}{i}  \binom{p-p_\zeta}{m-i} }{\binom{p}{m}}\]

This version considers an urn model with two types of balls, i.e.~an urn
model where the balls (node pairs) are of two kinds, edges or non-edges.
In total there are \[p-p_\zeta\] black balls and \(p_\zeta\) white
balls. One extracts \textbf{without replacement} \[m\] balls and is
interested in the probability to have at least \[m_\zeta\] white balls.

It is also possible to define a variant of Surprise that consider
instead of only two kind of balls, a total of \[C\] kind of balls,
meaning one for each community. This variant is based on the
multivariate hypergeometric distribution, same as before but with balls
of \[C\] different colors:

\[S_M = \prod \limits_c \dfrac{\binom{p_c}{m_c}}{\binom{p}{m}}\]

It is shown that both the original Surprise and the multivariate version
of it can be approximated to the \textbf{Asymptotical Surprise}, a
formulation that uses the relative entropy:

\[ -\log{S_M} \asym m D_{KL}(\mathbf{q} \| \left< \mathbf{q}\right>) = m \sum_c \dfrac{m_c}{m} \log\left(\dfrac{m_c/m}{p_c/p} \right)\]

In the case of the original Surprise one uses the binary
Kullback-Leibler divergence, namely

\[D_{KL}_{binary}(x \| y) = x \log \left(\frac{x}{y}\right) + (1-x)\log\left(\frac{(1-x)}{(1-y)}\right)\]

while for the multivariate variant Surprise the sum runs over all
communities:

\[-\log{S_M} \asym m D_{KL}(x \| y) = x \log \left(\frac{x}{y}\right) + (1-x)\log\left(\frac{(1-x)}{(1-y)}\right)\]

I have noticed that these two last formulations are extremely similar to
the stochastic block model introduced by Newman and Karrer, that instead
has the sum of pairs of blocks (rather than just on the diagonal as
MultiSurprise):

\[\mathcal{L}(G) = \sum \limits_{rs} \dfrac{m_{rs}}{2m}\log\left( \dfrac{m_{rs}}{n_r n_s/n^2}\right)\]

\[\mathcal{L}(G) = \sum \limits_{rs} \dfrac{m_{rs}}{2m}\log\left( \dfrac{m_{rs}}{n_r n_s/n^2}\right)\]

because in this model on undirected graphs pairs of blocks are counted,
then the \[2\] factor, so if one considers only community structure of
blocks and on undirected graphs:

\[\mathcal{L}(G | g) = \sum \limits_{r} \dfrac{m_{r}}{m}\log\left( \dfrac{m_{r}}{p_r}\right)\]

If one continues to read the Karrer and Newman paper, then the stubs are
considered instead of vertex pairs, and the degree-corrected stochastic
block model is considered, that reads:

\[
\mathcal{L} = \sum \limits_{rs} \dfrac{m_{rs}}{2m} \log \left( \dfrac{m_{rs}/2m}{(k_r/2m)(k_s/2m)}\right)
\]

coming back with the reasoning, consider only \[r==s\], then this
becomes focused on communities:

\[
\mathcal{L}_C = \sum \limits_{r} \dfrac{m_{r}}{m} \log \left( \dfrac{m_{rs}/2m}{(k_r/2m)^2}\right)
\]

multiply by \[m\]:

\[
m \mathcal{L}_C = mD_{KL}(\mathbf{q} \| \left< \mathbf{q}\right>)
\]

where here \[\mathbf{q}=(m_{11}/m, m_{12}/m, \ldots, m_{cc}/m)\] and
\[\left< \mathbf{q} \right >=(m_{11}/m, m_{12}/m, \ldots, m_{cc}/m)\]
and

therefore its original distribution is:

\[S_{CM} = \prod \limits_c \dfrac{\binom{p_c}{m_c}}{\binom{p}{m}}\]
