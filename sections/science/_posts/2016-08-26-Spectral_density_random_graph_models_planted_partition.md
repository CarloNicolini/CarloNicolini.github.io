---
layout: post
title: Comparing spectral densities of random graph models.
categories: science
date: 2016-08-26
---

Among the many graph measures that I think are useful for the comparison of two different networks, in the last months, a particular is emerging that is based on the comparison of graph spectra. In general the spectrum of a matrix is the set of all its eigenvalues. For graphs, when they are thought to come from some random graph model (Erdos-Renyi, Watts-Strogats, Barabasi-Albert or others), one can make this concept more concrete and talk about *spectral density*. Every random graph model is characterized by its spectral density and this probability distribution is a rather powerful tool to identify different graph models. 
Large networks generated by the same random process are found to have the same spectrum distribution, allowing us to use it as a "fingerprint" of graphs.
In a 2012 paper [Takahashi2012](#Takahashi2012), comparison of graph models in terms of statistical distribution comparison of their spectral density is suggested as a tool for the identification of differences between groups of brain networks. Additionally [Takahashi2012](#Takahashi2012) proposed general methods for model selection and network model parameter estimation, as well as a statistical procedure to test the nullity of divergence between two classes of complex networks. These brief notes try to summarize the main results of their paper and generates the illustrations of a proceedings books [Dehmer2015](#Dehmer2015).

## Spectral density
A graph $$G =(V,E)$$ is an ordered pair, where $$V =\{1, 2,\ldots, n\}$$ is a set of vertices and $$E$$ is a set of edges connecting the elements of $$V$$. All graphs considered in this chapter are undirected, that is, each edge $$e \in E$$ is an unordered pair of vertices. To learn statistical methods in graphs, we must first understand the concept of probability distribution over graphs. The theory behind it is the theory of random graphs, which studies the intersection between graph theory and probability theory. A random graph is a probability space $$(\Omega,F,P)$$, where the sample space $$\Omega$$ is a
nonempty set of graphs, the set of events $$F$$ is a collection of subsets of the sample space (usually is the power set of $$\Omega$$), and $$P$$ is a function that assigns a probability to each event. It is usual to describe a random graph by a sequence of steps to construct it. An algorithm that describes the construction of a random graph is called a random graph model. An example of random graphmodel is the Erdos-Renyi, in which the sample space $$\Omega$$ is the set of all graphs having $$n$$ labeled vertices, and $$m$$ edges (usually $$m$$ is a function of $$n$$). Each graph of $$\Omega$$ can be generated by selecting $$m$$
edges from the $$\binom{n}{2}$$ possible edges.Therefore, the set $$\Omega$$ has size $$\binom{\binom{n}{2}}{m}$$. Then, the probability to choose a graph from $$\Omega$$ is $$\left( \binom{\binom{n}{2}}{m} \right)^{-1}$$.

Suppose now that we take at random two graphs $$G_1$$ and $$G_2$$, each one of size $n$. If both graphs are from the same random graph model, then it is reasonable to expect that in the limit $$n \rightarrow \infty$$ they share some structural properties. By contrast if $$G_1$$ and $$G_2$$ are from different graph models, we may expect to find fundamental differences between their structural properties.

Given the graphs $$G_1$$ and $$G_2$$, can we measure the similarities between their structures? Is the probability of $$G_1$$ and $$G_2$$ being from the same random graph high? To answer these questions, we need a mathematical way to describe graph structural properties that are equal for graphs from the same random graph, but different for elements from distinct random graphs. [Takahashi](#Takahashi2012) proposed that the spectrumof a graph is an adequate summarization of the graph structure for this problem. In the following section, we define the graph spectrumand other spectrum-based concepts that describe a set of graph structural properties.

## Graph spectrum
Let $$G =(V,E)$$ be an undirected graph and n the number of vertices (i.e.,
$$n = |V|$$). The spectrum of $$G$$ is the set of eigenvalues of its adjacency matrix, which is denoted by $$A_G$$.As $$G$$ is undirected, if two vertices $$i$$ and $$j$$ are connected by an edge, then $$A_{G_{ij}} = 1$$, otherwise,$$A_{G_{ij}}=0$$ if $$i$$ and $$j$$ are not connected. We have $$A_G = A_G^T$$ and, therefore, all eigenvalues of the matrix $$A_G$$ are real.
Let $$\{ \lambda_1,\ldots \lambda_n \}$$ be the spectrum of $$G$$ such that $$\lambda_1 \geq \lambda_2 \geq \ldots \geq \lambda_n$$. The spectral graph theory studies graph spectrum properties and their association with the graph structure. We show some examples of this relationship below.
#### Useful facts about graph eigenvalues
1.  Let $$k_i$$ denote the degree of $$i$$. Then the eigenvalue $$\lambda_1$$ is at least $$ \frac{1}{n}\sum_{i=1}^n k_i$$.
2.  The graph $$G$$ is **bipartite** if and only if $$\lambda_n = -\lambda_1$$ (in general bipartite graphs have symmetric spectrum)
3.  If $$G$$ is connected, then the eigenvalue $$\lambda_1$$ is strictly larger than $$\lambda_2$$ and there exist a positive eigenvector of $$\lambda_1$$. The largest eigenvalue $$\lambda_1$$ is also called the Perron-Frobenius eigenvalue.
4.  Each vertex in $$V$$ is connected to exactly $$\lambda_1$$ vertices only if the vector of ones is an eigenvector of $$\lambda_1$$.
5.  Let $$C \subset V$$ such that each pair of vertices in $$C$$ are connected in $$G$$, i.e. $$C$$ is a clique in $$G$$. Then, the size of $$C$$ is at most $$\lambda_1 + 1$$.
6.  Let $$d$$ be the diameter of $$G$$. If $$G$$ is connected, then $$A_G$$ has at least $$d+1$$ distinct eigenvalues.

# Spectral Entropy

# Kernel density estimation

# Code
In the following pieces of code, we try to compute the spectral densities of some random graph models. To estimate the continuous distribution of the spectral densities we rely on a Montecarlo-like simulation. We generate many instances from the specific random graph model and compute their eigenvalues. We then average the eigenvalues and compute with the help of a kernel density estimator, the continuous density function. As density estimatore we use Gaussian Kernels where the bandwidth of the kernel is found by the Silverman criterion.

We now import all the Python libraries useful for this task:

    {% highlight python %}
    """
    See the book Mathias Dehmer,
    "Mathematical Foundations and Applications of Graph Entropy"
    Chapter 6 Statistical Methods in Graphs: Parameter Estimation, Model Selection, and Hypothesis Test
    """
    import networkx as nx
    import numpy as np
    import matplotlib.pyplot as plt
    import seaborn as sbn
    from numpy.linalg import eigvals
    from scipy import stats
    {% endhighlight %}

Then we focus on the estimation of the spectral density of the ER model $$G(n,p)$$ that in some sense is the canonical ensemble version of the $$G(n,m)$$ random graph model (the microcanonical ensemble where number of links is an hard constraint). We use a $$p=0.007$$ and generate 1000 random graphs of $$n=50$$ nodes, computing then the average eigenvalues.

    {% highlight python %}
    # Generate 1000 ER random graphs with the Erdos-Renyi model 
    # and compute their eigenvalues mean
    n = 50
    p = 0.007
    nsamples = 1000
    vs = np.array([0]*n)
    for i in range(0,nsamples):
        G = nx.gnp_random_graph(n,p)
        A = nx.to_numpy_matrix(G)
        v = np.real(eigvals(A))
        vs = vs + v
    vs = vs/nsamples
    {% endhighlight %}

We must divide the average eigenvalue by $$\sqrt(n)$$ and then estimate the Gaussian Kernel Density.

    {% highlight python %}
    vs = vs/(np.sqrt(n))
    kde = stats.gaussian_kde(vs,bw_method='silverman')
    x = np.linspace(vs.min(), vs.max(), 100)
    rho = kde(x)
    {% endhighlight %}

Finally we plot the empirical data together with the theoretical analytical estimate:

    {% highlight python %}
    plt.subplot(1,3,1)
    plt.plot(x,rho)
    plt.ylabel('Spectral density')
    plt.xlabel('Eigenvalues')
    plt.title('ER Model spectral density')
    plt.plot(x,0.5*np.log((4*np.pi**2)*x*(1-x))-0.5,'r')
    {% endhighlight %}


## References
- <a name="Dehmer2015"></a>Dehmer, M., Emmert-streib, F., Chen, Z., Li, X., Barabási, A., n.d. Mathematical Foundations and Applications of Graph Entropy “ Quantitative and Network Biology ” Advisory Board : Previous Volumes of this Series : Applied Statistics for Network Advances in Network Statistical Modelling of QSAR / QSPR Statistical Diagnost.

- <a name="Takahashi2012"></a>Takahashi, D.Y., Sato, J.R., Ferreira, C.E., Fujita, A., 2012. Discriminating Different Classes of Biological Networks by Analyzing the Graphs Spectra Distribution. PLoS One 7. doi:10.1371/journal.pone.0049949
